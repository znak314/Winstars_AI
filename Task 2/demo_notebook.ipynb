{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Demostration of the work\n",
    "The NER was trained in Google Collab (to have opportuniity to work with GPU), and Image Classifier was trained localy so some paths can be different."
   ],
   "metadata": {
    "id": "erZ4F1TIjaxM"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## BERT-based NER training\n",
    "Let's start with NER model training. For that purpose we will run NER training script. To start, we should download `simpletransformers`"
   ],
   "metadata": {
    "id": "oFbe1UkjjeLv"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install simpletransformers"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7CtwOS23kfhl",
    "outputId": "4a40e3d3-be98-401e-a4d2-efaf0f0a86b8"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting simpletransformers\n",
      "  Downloading simpletransformers-0.70.1-py3-none-any.whl.metadata (42 kB)\n",
      "\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/42.4 kB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m42.4/42.4 kB\u001B[0m \u001B[31m3.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from simpletransformers) (1.26.4)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from simpletransformers) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.47.0 in /usr/local/lib/python3.11/dist-packages (from simpletransformers) (4.67.1)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (from simpletransformers) (2024.11.6)\n",
      "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.11/dist-packages (from simpletransformers) (4.48.3)\n",
      "Collecting datasets (from simpletransformers)\n",
      "  Downloading datasets-3.3.2-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from simpletransformers) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from simpletransformers) (1.6.1)\n",
      "Collecting seqeval (from simpletransformers)\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m43.6/43.6 kB\u001B[0m \u001B[31m3.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Requirement already satisfied: tensorboard in /usr/local/lib/python3.11/dist-packages (from simpletransformers) (2.18.0)\n",
      "Collecting tensorboardx (from simpletransformers)\n",
      "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from simpletransformers) (2.2.2)\n",
      "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from simpletransformers) (0.21.0)\n",
      "Requirement already satisfied: wandb>=0.10.32 in /usr/local/lib/python3.11/dist-packages (from simpletransformers) (0.19.7)\n",
      "Collecting streamlit (from simpletransformers)\n",
      "  Downloading streamlit-1.42.2-py2.py3-none-any.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from simpletransformers) (0.2.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->simpletransformers) (3.17.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->simpletransformers) (0.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->simpletransformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->simpletransformers) (6.0.2)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers>=4.31.0->simpletransformers) (0.5.3)\n",
      "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.10.32->simpletransformers) (8.1.8)\n",
      "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.10.32->simpletransformers) (0.4.0)\n",
      "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.10.32->simpletransformers) (3.1.44)\n",
      "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb>=0.10.32->simpletransformers) (4.3.6)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.10.32->simpletransformers) (4.25.6)\n",
      "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.10.32->simpletransformers) (5.9.5)\n",
      "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.10.32->simpletransformers) (2.10.6)\n",
      "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.10.32->simpletransformers) (2.22.0)\n",
      "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb>=0.10.32->simpletransformers) (1.3.5)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb>=0.10.32->simpletransformers) (75.1.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb>=0.10.32->simpletransformers) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->simpletransformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->simpletransformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->simpletransformers) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->simpletransformers) (2025.1.31)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->simpletransformers) (18.1.0)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets->simpletransformers)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting xxhash (from datasets->simpletransformers)\n",
      "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multiprocess<0.70.17 (from datasets->simpletransformers)\n",
      "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: fsspec<=2024.12.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets->simpletransformers) (2024.10.0)\n",
      "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->simpletransformers) (3.11.13)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->simpletransformers) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->simpletransformers) (2025.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->simpletransformers) (2025.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->simpletransformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->simpletransformers) (3.5.0)\n",
      "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->simpletransformers) (5.5.0)\n",
      "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->simpletransformers) (1.9.0)\n",
      "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->simpletransformers) (5.5.2)\n",
      "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->simpletransformers) (11.1.0)\n",
      "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->simpletransformers) (13.9.4)\n",
      "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from streamlit->simpletransformers) (9.0.0)\n",
      "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit->simpletransformers) (0.10.2)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit->simpletransformers)\n",
      "  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m44.3/44.3 kB\u001B[0m \u001B[31m4.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit->simpletransformers)\n",
      "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit->simpletransformers) (6.4.2)\n",
      "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.11/dist-packages (from tensorboard->simpletransformers) (1.4.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.11/dist-packages (from tensorboard->simpletransformers) (1.70.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.11/dist-packages (from tensorboard->simpletransformers) (3.7)\n",
      "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.11/dist-packages (from tensorboard->simpletransformers) (1.17.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from tensorboard->simpletransformers) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from tensorboard->simpletransformers) (3.1.3)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit->simpletransformers) (3.1.5)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit->simpletransformers) (4.23.0)\n",
      "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit->simpletransformers) (1.28.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->simpletransformers) (2.4.6)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->simpletransformers) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->simpletransformers) (25.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->simpletransformers) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->simpletransformers) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->simpletransformers) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->simpletransformers) (1.18.3)\n",
      "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (4.0.12)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb>=0.10.32->simpletransformers) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb>=0.10.32->simpletransformers) (2.27.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich<14,>=10.14.0->streamlit->simpletransformers) (2.18.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.11/dist-packages (from werkzeug>=1.0.1->tensorboard->simpletransformers) (3.0.2)\n",
      "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.10.32->simpletransformers) (5.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (2024.10.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit->simpletransformers) (0.23.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit->simpletransformers) (0.1.2)\n",
      "Downloading simpletransformers-0.70.1-py3-none-any.whl (316 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m316.3/316.3 kB\u001B[0m \u001B[31m24.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading datasets-3.3.2-py3-none-any.whl (485 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m485.4/485.4 kB\u001B[0m \u001B[31m29.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading streamlit-1.42.2-py2.py3-none-any.whl (9.6 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m9.6/9.6 MB\u001B[0m \u001B[31m73.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m101.7/101.7 kB\u001B[0m \u001B[31m9.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m116.3/116.3 kB\u001B[0m \u001B[31m12.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m143.5/143.5 kB\u001B[0m \u001B[31m14.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.9/6.9 MB\u001B[0m \u001B[31m77.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m79.1/79.1 kB\u001B[0m \u001B[31m8.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m194.8/194.8 kB\u001B[0m \u001B[31m13.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hBuilding wheels for collected packages: seqeval\n",
      "  Building wheel for seqeval (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16161 sha256=4bd232f98d2d4174f22e358d23fe8a7da6c8ec7bd6867c4070bc32d2fd6b1d32\n",
      "  Stored in directory: /root/.cache/pip/wheels/bc/92/f0/243288f899c2eacdfa8c5f9aede4c71a9bad0ee26a01dc5ead\n",
      "Successfully built seqeval\n",
      "Installing collected packages: xxhash, watchdog, tensorboardx, dill, pydeck, multiprocess, seqeval, datasets, streamlit, simpletransformers\n",
      "Successfully installed datasets-3.3.2 dill-0.3.8 multiprocess-0.70.16 pydeck-0.9.1 seqeval-1.2.2 simpletransformers-0.70.1 streamlit-1.42.2 tensorboardx-2.6.2.2 watchdog-6.0.0 xxhash-3.5.0\n"
     ]
    }
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "In general, BERT-NER training run command looks like:\n",
    "```bash\n",
    "python train.py --file_path \"path_to_dataset\" --epochs 3 --learning_rate 2e-4 --batch_size 16 --output_dir \"output_dir_path\"\n",
    "```\n",
    "\n",
    "For me it was:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "21DM2lV3jUdx",
    "outputId": "5ca0a755-e175-456b-ac69-3e7ff061be38"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "2025-03-01 21:25:18.047598: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740864318.068185     961 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740864318.074362     961 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-03-01 21:25:18.095109: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "config.json: 100% 570/570 [00:00<00:00, 3.51MB/s]\n",
      "model.safetensors: 100% 436M/436M [00:01<00:00, 242MB/s]\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "tokenizer_config.json: 100% 49.0/49.0 [00:00<00:00, 410kB/s]\n",
      "vocab.txt: 100% 213k/213k [00:00<00:00, 53.7MB/s]\n",
      "tokenizer.json: 100% 436k/436k [00:00<00:00, 42.7MB/s]\n",
      "100% 1/1 [00:00<00:00,  4.40it/s]\n",
      "Epoch 1 of 3:   0% 0/3 [00:00<?, ?it/s]\n",
      "Running Epoch 1 of 3:   0% 0/20 [00:00<?, ?it/s]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.6804:   0% 0/20 [00:05<?, ?it/s]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.6804:   5% 1/20 [00:14<04:30, 14.23s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.6578:   5% 1/20 [00:19<04:30, 14.23s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.6578:  10% 2/20 [00:26<03:55, 13.10s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.3579:  10% 2/20 [00:31<03:55, 13.10s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.3579:  15% 3/20 [00:37<03:29, 12.33s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.3116:  15% 3/20 [00:41<03:29, 12.33s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.3116:  20% 4/20 [00:49<03:10, 11.93s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.2284:  20% 4/20 [00:52<03:10, 11.93s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.2284:  25% 5/20 [01:00<02:56, 11.75s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.2022:  25% 5/20 [01:04<02:56, 11.75s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.2022:  30% 6/20 [01:11<02:41, 11.52s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.1717:  30% 6/20 [01:15<02:41, 11.52s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.1717:  35% 7/20 [01:22<02:25, 11.22s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.1424:  35% 7/20 [01:27<02:25, 11.22s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.1424:  40% 8/20 [01:33<02:15, 11.33s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.1312:  40% 8/20 [01:37<02:15, 11.33s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.1312:  45% 9/20 [01:45<02:04, 11.36s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.1604:  45% 9/20 [01:48<02:04, 11.36s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.1604:  50% 10/20 [01:56<01:54, 11.40s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.0629:  50% 10/20 [02:00<01:54, 11.40s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.0629:  55% 11/20 [02:07<01:40, 11.21s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.0944:  55% 11/20 [02:11<01:40, 11.21s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.0944:  60% 12/20 [02:17<01:27, 10.95s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.0457:  60% 12/20 [02:22<01:27, 10.95s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.0457:  65% 13/20 [02:29<01:17, 11.09s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.0836:  65% 13/20 [02:32<01:17, 11.09s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.0836:  70% 14/20 [02:40<01:06, 11.15s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.0579:  70% 14/20 [02:44<01:06, 11.15s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.0579:  75% 15/20 [02:52<00:56, 11.23s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.0587:  75% 15/20 [02:55<00:56, 11.23s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.0587:  80% 16/20 [03:02<00:44, 11.04s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.0323:  80% 16/20 [03:06<00:44, 11.04s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.0323:  85% 17/20 [03:13<00:32, 10.84s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.0365:  85% 17/20 [03:17<00:32, 10.84s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.0365:  90% 18/20 [03:25<00:22, 11.23s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.0702:  90% 18/20 [03:28<00:22, 11.23s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.0702:  95% 19/20 [03:37<00:11, 11.62s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.0274:  95% 19/20 [03:40<00:11, 11.62s/it]\u001B[A\n",
      "Epochs 1/3. Running Loss:    0.0274: 100% 20/20 [03:46<00:00, 11.35s/it]\n",
      "Epoch 2 of 3:  33% 1/3 [03:58<07:56, 238.29s/it]\n",
      "Running Epoch 2 of 3:   0% 0/20 [00:00<?, ?it/s]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0057:   0% 0/20 [00:04<?, ?it/s]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0057:   5% 1/20 [00:11<03:34, 11.29s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0073:   5% 1/20 [00:15<03:34, 11.29s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0073:  10% 2/20 [00:23<03:28, 11.59s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0097:  10% 2/20 [00:26<03:28, 11.59s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0097:  15% 3/20 [00:34<03:17, 11.60s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0322:  15% 3/20 [00:38<03:17, 11.60s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0322:  20% 4/20 [00:46<03:05, 11.60s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0069:  20% 4/20 [00:49<03:05, 11.60s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0069:  25% 5/20 [00:57<02:50, 11.37s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0234:  25% 5/20 [01:01<02:50, 11.37s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0234:  30% 6/20 [01:08<02:36, 11.16s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0155:  30% 6/20 [01:12<02:36, 11.16s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0155:  35% 7/20 [01:19<02:26, 11.30s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0166:  35% 7/20 [01:23<02:26, 11.30s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0166:  40% 8/20 [01:31<02:16, 11.37s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0863:  40% 8/20 [01:34<02:16, 11.37s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0863:  45% 9/20 [01:42<02:05, 11.38s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0070:  45% 9/20 [01:45<02:05, 11.38s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0070:  50% 10/20 [01:53<01:52, 11.27s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0376:  50% 10/20 [01:57<01:52, 11.27s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0376:  55% 11/20 [02:04<01:39, 11.06s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0011:  55% 11/20 [02:08<01:39, 11.06s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0011:  60% 12/20 [02:15<01:30, 11.27s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0219:  60% 12/20 [02:19<01:30, 11.27s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0219:  65% 13/20 [02:27<01:20, 11.45s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0311:  65% 13/20 [02:31<01:20, 11.45s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0311:  70% 14/20 [02:39<01:09, 11.53s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0151:  70% 14/20 [02:42<01:09, 11.53s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0151:  75% 15/20 [02:51<00:57, 11.54s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0308:  75% 15/20 [02:54<00:57, 11.54s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0308:  80% 16/20 [03:01<00:44, 11.20s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0483:  80% 16/20 [03:06<00:44, 11.20s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0483:  85% 17/20 [03:12<00:33, 11.22s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0255:  85% 17/20 [03:16<00:33, 11.22s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0255:  90% 18/20 [03:24<00:22, 11.37s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0092:  90% 18/20 [03:28<00:22, 11.37s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0092:  95% 19/20 [03:36<00:11, 11.48s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0078:  95% 19/20 [03:38<00:11, 11.48s/it]\u001B[A\n",
      "Epochs 2/3. Running Loss:    0.0078: 100% 20/20 [03:44<00:00, 11.21s/it]\n",
      "Epoch 3 of 3:  67% 2/3 [08:01<04:00, 240.97s/it]\n",
      "Running Epoch 3 of 3:   0% 0/20 [00:00<?, ?it/s]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0252:   0% 0/20 [00:03<?, ?it/s]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0252:   5% 1/20 [00:11<03:38, 11.51s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0030:   5% 1/20 [00:14<03:38, 11.51s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0030:  10% 2/20 [00:22<03:23, 11.32s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0010:  10% 2/20 [00:26<03:23, 11.32s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0010:  15% 3/20 [00:32<03:03, 10.82s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0039:  15% 3/20 [00:37<03:03, 10.82s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0039:  20% 4/20 [00:44<02:55, 10.98s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0093:  20% 4/20 [00:47<02:55, 10.98s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0093:  25% 5/20 [00:55<02:46, 11.12s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0006:  25% 5/20 [00:58<02:46, 11.12s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0006:  30% 6/20 [01:07<02:37, 11.25s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0072:  30% 6/20 [01:10<02:37, 11.25s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0072:  35% 7/20 [01:17<02:24, 11.11s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0007:  35% 7/20 [01:21<02:24, 11.11s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0007:  40% 8/20 [01:28<02:11, 10.92s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0010:  40% 8/20 [01:32<02:11, 10.92s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0010:  45% 9/20 [01:39<02:01, 11.03s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0008:  45% 9/20 [01:43<02:01, 11.03s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0008:  50% 10/20 [01:50<01:51, 11.11s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0180:  50% 10/20 [01:54<01:51, 11.11s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0180:  55% 11/20 [02:02<01:40, 11.18s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0007:  55% 11/20 [02:05<01:40, 11.18s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0007:  60% 12/20 [02:13<01:28, 11.06s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0017:  60% 12/20 [02:16<01:28, 11.06s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0017:  65% 13/20 [02:23<01:16, 10.92s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0013:  65% 13/20 [02:28<01:16, 10.92s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0013:  70% 14/20 [02:35<01:06, 11.08s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0072:  70% 14/20 [02:38<01:06, 11.08s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0072:  75% 15/20 [02:46<00:56, 11.20s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0245:  75% 15/20 [02:49<00:56, 11.20s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0245:  80% 16/20 [02:58<00:45, 11.30s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0014:  80% 16/20 [03:01<00:45, 11.30s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0014:  85% 17/20 [03:08<00:33, 11.12s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0003:  85% 17/20 [03:12<00:33, 11.12s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0003:  90% 18/20 [03:19<00:22, 11.11s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0240:  90% 18/20 [03:24<00:22, 11.11s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0240:  95% 19/20 [03:31<00:11, 11.32s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0004:  95% 19/20 [03:34<00:11, 11.32s/it]\u001B[A\n",
      "Epochs 3/3. Running Loss:    0.0004: 100% 20/20 [03:41<00:00, 11.06s/it]\n",
      "Epoch 3 of 3: 100% 3/3 [12:03<00:00, 241.23s/it]\n",
      "100% 1/1 [00:00<00:00, 13.54it/s]\n",
      "Running Evaluation: 100% 18/18 [00:59<00:00,  3.31s/it]\n",
      "/usr/local/lib/python3.11/dist-packages/seqeval/metrics/sequence_labeling.py:171: UserWarning: ANIMAL seems not to be NE tag.\n",
      "  warnings.warn('{} seems not to be NE tag.'.format(chunk))\n",
      "Evaluation Results: {'eval_loss': 0.0003774860698386975, 'precision': 1.0, 'recall': 1.0, 'f1_score': 1.0}\n"
     ]
    }
   ],
   "source": "!python /content/drive/MyDrive/Winstars/Task2/NER/train.py --file_path /content/drive/MyDrive/Winstars/Task2/data/NER_data/test_task_NER_dataset.csv --epochs 3 --learning_rate 2e-4 --batch_size 16 --output_dir models/trained_ner_model"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We have reached perfect accuracy on the test_data.\n",
    "\n",
    "### Image Classifie ResNet training\n",
    "For image classificator training you can use command:\n",
    "\n",
    "```bash\n",
    "python train.py --dataset_path \"dataset_path\" --epochs 30 --batch_size 32\n",
    "```\n",
    "\n",
    "For me it looked like:\n",
    "```bash\n",
    "python \"C:\\Users\\pizna\\PycharmProjects\\Winstars\\Task 2\\Image_Classifier\\train.py\" --dataset_path \"C:\\Users\\pizna\\PycharmProjects\\Winstars\\Task 2\\data\\image_dataset\" --epochs 3 --batch_size 16\n",
    "```\n",
    "\n",
    "This is my model training process screen:\n",
    "![training_screen](https://i.postimg.cc/sgntKfF4/training-screen.png)\n",
    "\n",
    "Due to the lack of time and computing resources, we trained only on 3 epochs, but it is worth increasing the number to 10. After that I have all my models and ready to the inference. You can download trained models [here](https://drive.google.com/drive/folders/1xkKDfIRDH2l8-c6OFX0boT-v825l5R2n)"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We have reached perfect accuracy on the test_data.\n",
    "\n",
    "### Image Classifie ResNet training\n",
    "For image classificator training you can use command:\n",
    "\n",
    "```bash\n",
    "python train.py --dataset_path \"dataset_path\" --epochs 30 --batch_size 32\n",
    "```\n",
    "\n",
    "For me it looked like:\n",
    "```bash\n",
    "python \"C:\\Users\\pizna\\PycharmProjects\\Winstars\\Task 2\\Image_Classifier\\train.py\" --dataset_path \"C:\\Users\\pizna\\PycharmProjects\\Winstars\\Task 2\\data\\image_dataset\" --epochs 3 --batch_size 16\n",
    "```\n",
    "\n",
    "This is my model training process screen:\n",
    "![training_screen](https://i.postimg.cc/sgntKfF4/training-screen.png)\n",
    "\n",
    "Due to the lack of time and computing resources, we trained only on 3 epochs, but it is worth increasing the number to 10. After that I have all my models and ready to the inference. You can download trained models [here](https://drive.google.com/drive/folders/1xkKDfIRDH2l8-c6OFX0boT-v825l5R2n)\n",
    "\n",
    "## NER Model Inference\n",
    "\n",
    "NER model inference run command looks like:\n",
    "```bash\n",
    "python inference.py --model_path \"models/trained_ner_model\" --input_text \"some_text\"\n",
    "```\n",
    "\n",
    "For me it was:"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T09:22:13.208032Z",
     "start_time": "2025-03-02T09:21:47.210447Z"
    }
   },
   "cell_type": "code",
   "source": "!python \"C:\\Users\\pizna\\PycharmProjects\\Winstars\\Task 2\\NER\\inference.py\" --model_path \"C:\\Users\\pizna\\PycharmProjects\\Winstars\\Task 2\\models\\trained_ner_model\" --input_text \"The cat jumped over the fence and ran into the garden.\"",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:\n",
      "[[{'The': 'O'}, {'cat': 'ANIMAL'}, {'jumped': 'O'}, {'over': 'O'}, {'the': 'O'}, {'fence': 'O'}, {'and': 'O'}, {'ran': 'O'}, {'into': 'O'}, {'the': 'O'}, {'garden.': 'O'}]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-02 11:21:50.554346: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-02 11:21:51.353055: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]2025-03-02 11:22:01.341842: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-02 11:22:02.505811: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "\n",
      "100%|##########| 1/1 [00:13<00:00, 13.62s/it]\n",
      "100%|##########| 1/1 [00:13<00:00, 13.62s/it]\n",
      "\n",
      "Running Prediction:   0%|          | 0/1 [00:00<?, ?it/s]\n",
      "Running Prediction: 100%|##########| 1/1 [00:01<00:00,  1.12s/it]\n",
      "Running Prediction: 100%|##########| 1/1 [00:01<00:00,  1.12s/it]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As we see, model successfully recognized cat as an Animal. Predictions have format token:label, in pipeline I am aditionally post-processing predictions, but for the inference it is important to us to see all the labels."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Image classifier Inference\n",
    "Image classifier ResNet model inference run command looks like:\n",
    "\n",
    "```bash\n",
    "python inference.py --img_path \"path_to_some_img\" --model_path \"path_to_classifier_model\"\n",
    "```"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's check the model work on spider image"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T09:27:42.610157Z",
     "start_time": "2025-03-02T09:27:37.383587Z"
    }
   },
   "cell_type": "code",
   "source": "!python \"C:\\Users\\pizna\\PycharmProjects\\Winstars\\Task 2\\Image_Classifier\\inference.py\" --img_path \"C:\\Users\\pizna\\PycharmProjects\\Winstars\\Task 2\\data\\example_images\\spider.jpg\" --model_path \"C:\\Users\\pizna\\PycharmProjects\\Winstars\\Task 2\\models\\animal_classifier.h5\"",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m====================\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 269ms/step\n",
      "\u001B[1m1/1\u001B[0m \u001B[32m====================\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 280ms/step\n",
      "Predicted Class: spider\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-02 11:27:37.720740: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-02 11:27:38.556780: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-03-02 11:27:41.311818: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As we see, model classified class corectly."
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Final pipeline\n",
    "\n",
    "Let's initialize some paths variables that we will need"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T09:32:33.434555Z",
     "start_time": "2025-03-02T09:32:33.417664Z"
    }
   },
   "cell_type": "code",
   "source": "from pipeline import Pipeline",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T09:30:53.086406Z",
     "start_time": "2025-03-02T09:30:53.066622Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ner_model_path = \"models/trained_ner_model\"\n",
    "classifier_model_path = \"models/animal_classifier.h5\""
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Let's initialize pipeline instance"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T09:32:37.208566Z",
     "start_time": "2025-03-02T09:32:36.516159Z"
    }
   },
   "cell_type": "code",
   "source": "pipeline = Pipeline(NER_model_path=ner_model_path, classifier_model_path=classifier_model_path)",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T09:34:27.453131Z",
     "start_time": "2025-03-02T09:34:15.332606Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_path = \"data\\example_images\\spider.jpg\"\n",
    "text = \"The spider spun a delicate web in the corner of the room.\"\n",
    "\n",
    "result = pipeline.predict_animal_on_image(image_path, text)\n",
    "print(result)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.19s/it]\n",
      "Running Prediction: 100%|██████████| 1/1 [00:01<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m1s\u001B[0m 562ms/step\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As we see, script returns correct results. In text NER model succesfully identified spider, while ResNet succesfully classified spider on image.\n",
    "\n",
    "Let's explore some edge cases\n",
    "\n",
    "1) Animal classified in text, but not in image"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T09:39:03.812632Z",
     "start_time": "2025-03-02T09:38:52.978102Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_path = \"data\\example_images\\\\butterfly.png\"\n",
    "text = \"As the sun set over the meadow, a vibrant butterfly with golden wings gently landed on a blooming lavender, its delicate movements barely disturbing the peaceful atmosphere.\"\n",
    "\n",
    "result = pipeline.predict_animal_on_image(image_path, text)\n",
    "print(result)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.46s/it]\n",
      "Running Prediction: 100%|██████████| 1/1 [00:00<00:00,  8.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 59ms/step\n",
      "False\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Result is expected.\n",
    "\n",
    "2) Now let's create a text without animals mentions and give the model image with animal."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T09:40:49.725953Z",
     "start_time": "2025-03-02T09:40:39.307586Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_path = \"data\\example_images\\\\butterfly.png\"\n",
    "text = \"As the sun set, the sky turned a beautiful shade of orange.\"\n",
    "\n",
    "result = pipeline.predict_animal_on_image(image_path, text)\n",
    "print(result)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.16s/it]\n",
      "Running Prediction: 100%|██████████| 1/1 [00:00<00:00,  7.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No animals in text\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As we see, script gives a message that there aren't any animals in text.\n",
    "\n",
    "3. Let's сreate a sentence that mentions several animals at once, and the animal in the picture is not the first to be mentioned."
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T09:44:44.706568Z",
     "start_time": "2025-03-02T09:44:34.447146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_path = \"data\\example_images\\horse.jpeg\"\n",
    "text = \"The cat, cow and horse played together in the yard, chasing each other under the bright afternoon sun.\"\n",
    "\n",
    "result = pipeline.predict_animal_on_image(image_path, text)\n",
    "print(result)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:09<00:00,  9.94s/it]\n",
      "Running Prediction: 100%|██████████| 1/1 [00:00<00:00,  8.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 29ms/step"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 48ms/step\n",
      "True\n"
     ]
    }
   ],
   "execution_count": 24
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As we see, we can define animal despite the position in text"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "4. Make a grammatical error when writing the name of an animal"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T09:46:00.629782Z",
     "start_time": "2025-03-02T09:45:50.201813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_path = \"data\\example_images\\spider.jpg\"\n",
    "text = \"The spiider spun a web in the corner of the room, waiting for its next meal.\"\n",
    "\n",
    "result = pipeline.predict_animal_on_image(image_path, text)\n",
    "print(result)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.20s/it]\n",
      "Running Prediction: 100%|██████████| 1/1 [00:00<00:00,  8.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No animals in text\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "As we can see, our NER model can't handle grammaticaly incorect words.\n",
    "\n",
    "5. Let's use sentence with synonim of some image class. Let it be 'spider' and 'arachnid'"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-02T09:50:50.836677Z",
     "start_time": "2025-03-02T09:50:05.381890Z"
    }
   },
   "cell_type": "code",
   "source": [
    "image_path = \"data\\example_images\\spider.jpg\"\n",
    "text = \"The arachnid quickly spun its web between the branches of the tree.\"\n",
    "\n",
    "result = pipeline.predict_animal_on_image(image_path, text)\n",
    "print(result)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:43<00:00, 43.50s/it]\n",
      "Running Prediction: 100%|██████████| 1/1 [00:00<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001B[1m1/1\u001B[0m \u001B[32m━━━━━━━━━━━━━━━━━━━━\u001B[0m\u001B[37m\u001B[0m \u001B[1m0s\u001B[0m 298ms/step\n",
      "False\n"
     ]
    }
   ],
   "execution_count": 26
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As we can see, we were able to recognize 'arachnid' as Animal, but our models prediction outputs don't have synonims postprocessing mechanism."
  }
 ]
}
